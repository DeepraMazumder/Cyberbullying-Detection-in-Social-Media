{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3n9SRvq_vWr2"
      },
      "outputs": [],
      "source": [
        "# Add module path\n",
        "import sys\n",
        "sys.path.append('../Artifacts')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WCqUreqVvWuX"
      },
      "outputs": [],
      "source": [
        "# Import the saved function\n",
        "from CyberbullyingSummarisation import analyze_cyberbullying"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "VSjldIfQCopP",
        "outputId": "15c98b93-0c80-4f4e-fa2a-15805e072482"
      },
      "outputs": [],
      "source": [
        "# Get user input and analyze\n",
        "user_input = input(\"Enter a sentence to classify: \")\n",
        "result = analyze_cyberbullying(user_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RIh-J_HCor3",
        "outputId": "baaad95f-0052-4ac0-b246-27e41b175c1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INPUT SENTENCE: He is a nigga and his son is a monkey\n",
            "\n",
            "CATEGORY: Race/Ethnicity related cyberbullying\n",
            "\n",
            "SUGGESTED ALTERNATIVES:\n",
            "\n",
            "1. He and his son are different.\n",
            "2. Their appearances differ.\n",
            "\n",
            "\n",
            "HARMFUL CONTENT IDENTIFICATION:\n",
            "\n",
            " ðŸ”´ nigga\n",
            " ðŸ”´ monkey\n",
            "\n",
            "\n",
            "TOTAL WORDS: 10\n",
            "\n",
            "FLAGGED PERCENTAGE: 20% (2 Harmful Words / 10 Total Words)\n",
            "\n",
            "REASON:\n",
            "\n",
            "The sentence uses racial slurs (nigga and monkey) to denigrate someone based on their race and ethnicity.  This constitutes racial cyberbullying.\n"
          ]
        }
      ],
      "source": [
        "# Combine user input and result for display and saving\n",
        "final_output = f\"INPUT SENTENCE: {user_input}\\n\\n{result}\"\n",
        "\n",
        "# Print the result\n",
        "print(final_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CReqRF4JDBoo",
        "outputId": "d2878dbc-0038-41e3-f661-e0a9e5718871"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary saved successfully\n"
          ]
        }
      ],
      "source": [
        "# Save the summary to a file\n",
        "with open('../Artifacts/CyberbullyingSummary.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write(final_output)\n",
        "\n",
        "print(f\"Summary saved successfully\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
