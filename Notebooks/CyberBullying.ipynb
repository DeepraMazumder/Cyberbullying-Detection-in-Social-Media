{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gepUz0AdE-Gw",
        "outputId": "3dadba47-e731-4fa8-db24-3019ac962e9e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Text Processing Libraries\n",
        "import re\n",
        "from cleantext import clean\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# NLTK for Natural Language Processing\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Sklearn Libraries for Preprocessing, Model Training, and Evaluation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc, multilabel_confusion_matrix\n",
        "\n",
        "# Machine Learning Models\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import svm\n",
        "\n",
        "# Boosting Algorithms\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# Suppressing Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# NLTK Downloads\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# For saving the model\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Um7Ugnk43Gs-"
      },
      "source": [
        "# DATA EXPLORATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blQa84q0E_1Q"
      },
      "outputs": [],
      "source": [
        "# Loading the dataset\n",
        "df = pd.read_csv('../Dataset/OriginalDataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hbVh-9tikjO",
        "outputId": "3b03802d-83fd-40bc-a806-b5c748d9f004"
      },
      "outputs": [],
      "source": [
        "# Displaying the first few rows of the dataset\n",
        "print(\"Dataset Overview:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zdP0KupZWi6",
        "outputId": "b7d7f407-8d16-4885-830a-33c5259036bc"
      },
      "outputs": [],
      "source": [
        "# Shape of the dataset\n",
        "print(\"Shape of the Dataset:\", df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJrFpbp_ZWlR",
        "outputId": "827d0c54-156b-4a09-c41b-492b70becae5"
      },
      "outputs": [],
      "source": [
        "# Basic Information about the Dataset\n",
        "print(\"Dataset Info:\")\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjTQHMx5ZWn0",
        "outputId": "89d34121-121a-42ac-af47-deaf79986ac8"
      },
      "outputs": [],
      "source": [
        "# Summary statistics of the dataset\n",
        "print(\"Dataset Description:\")\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS1BN4e1125U"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "9-fbWCjYe5r5",
        "outputId": "b8405f74-9d12-4450-ba46-6c637ba895df"
      },
      "outputs": [],
      "source": [
        "# Class distribution visualization\n",
        "sns.countplot(x='label', data=df, palette='Set2')\n",
        "plt.title('CLASS DISTRIBUTION')\n",
        "plt.xlabel('CATEGORIES')\n",
        "plt.ylabel('COUNT')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "9GYE36iUe5uR",
        "outputId": "36fe13fd-42c8-4668-8353-b1e833f7351f"
      },
      "outputs": [],
      "source": [
        "# Pie chart for class distribution\n",
        "df['label'].value_counts().plot.pie(autopct='%1.1f%%', startangle=90, colors=sns.color_palette('Set2', 5))\n",
        "plt.title('PROPORTION OF DIFFERENT CLASSES')\n",
        "plt.ylabel('')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "0kgJr0zke5wz",
        "outputId": "9dc21012-2d2e-429e-d1a0-8f53f4a54cbd"
      },
      "outputs": [],
      "source": [
        "# Length of tweets analysis\n",
        "df['tweet_length'] = df['text'].apply(len)\n",
        "\n",
        "sns.histplot(df['tweet_length'], kde=True, color='purple')\n",
        "plt.title('TWEET DISTRIBUTION ANALYSIS')\n",
        "plt.xlabel('TWEET LENGTH')\n",
        "plt.ylabel('FREQUENCY')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "J9HLOVZae5zR",
        "outputId": "bdaa42e0-ea73-4e62-9e1f-b2322026d529"
      },
      "outputs": [],
      "source": [
        "# Tweet length distribution per class\n",
        "sns.boxplot(x='label', y='tweet_length', data=df, palette='Set3')\n",
        "plt.title('TWEET DISTRIBUTION PER CATEGORY')\n",
        "plt.xlabel('CATEGORIES')\n",
        "plt.ylabel('TWEET LENGTH')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "D5um_aIQkCVM",
        "outputId": "1e471440-e384-442e-cf0c-950f3d3cc769"
      },
      "outputs": [],
      "source": [
        "# Word cloud visualization for each class in a 2x2 grid\n",
        "def generate_wordcloud_2x2(df):\n",
        "    categories = df['label'].unique()\n",
        "    fig, axs = plt.subplots(2, 2, figsize=(10, 6))\n",
        "\n",
        "    axs = axs.flatten()  # Flattening to easily iterate over axes\n",
        "    for i, category in enumerate(categories):\n",
        "        category_data = df[df['label'] == category]['text']\n",
        "        wc = WordCloud(width=800, height=400, max_words=200, background_color='white').generate(' '.join(category_data))\n",
        "        axs[i].imshow(wc, interpolation='bilinear')\n",
        "        axs[i].set_title(f'WORD CLOUD FOR {category}')\n",
        "        axs[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Generate word cloud for each category in 2x2 layout\n",
        "generate_wordcloud_2x2(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "rOvRpnMhg4Zg",
        "outputId": "77876759-bc8c-4475-a43a-4fb3480a3f5f"
      },
      "outputs": [],
      "source": [
        "# Most common words in each class using CountVectorizer\n",
        "vectorizer = CountVectorizer(stop_words='english', max_features=20)\n",
        "X = vectorizer.fit_transform(df['text'])\n",
        "\n",
        "# Barplot of most common words\n",
        "common_words = vectorizer.get_feature_names_out()\n",
        "word_counts = X.sum(axis=0).A1\n",
        "common_word_df = pd.DataFrame({'word': common_words, 'count': word_counts})\n",
        "\n",
        "sns.barplot(x='count', y='word', data=common_word_df.sort_values(by='count', ascending=False), palette='viridis')\n",
        "plt.title('TOP 20 MOST COMMON WORDS IN TWEETS')\n",
        "plt.xlabel('COUNT')\n",
        "plt.ylabel('WORDS')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHT4hJOh1zwm"
      },
      "source": [
        "# DATA PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnW_8gOfYgBc"
      },
      "outputs": [],
      "source": [
        "# Function to clean a given sentence by removing or modifying unwanted elements\n",
        "def clean_sentence(text):\n",
        "    # Use the clean-text library to perform various cleaning tasks on the text\n",
        "    cleaned_text = clean(\n",
        "        text,\n",
        "        to_ascii=True,               # Convert Unicode characters to their closest ASCII equivalent\n",
        "        lower=True,                  # Convert all characters in the text to lowercase\n",
        "        no_line_breaks=True,         # Remove line breaks to make the text a single line\n",
        "        no_urls=True,                # Remove any URLs from the text\n",
        "        no_emails=True,              # Remove email addresses\n",
        "        no_phone_numbers=True,       # Remove phone numbers\n",
        "        no_numbers=True,             # Remove all numeric values (e.g., \"123\")\n",
        "        no_digits=True,              # Remove digit characters (e.g., \"1\", \"2\")\n",
        "        no_currency_symbols=True,    # Remove any currency symbols (e.g., \"$\", \"€\")\n",
        "        no_punct=True,               # Remove punctuation marks (e.g., \".\", \",\", \"!\")\n",
        "        replace_with_punct=\"\",       # Specify what to replace punctuation marks with\n",
        "        replace_with_url=\"\",         # Specify what to replace URLs with\n",
        "        replace_with_email=\"\",       # Specify what to replace email addresses with\n",
        "        replace_with_phone_number=\"\",# Specify what to replace phone numbers with\n",
        "        replace_with_number=\"\",      # Specify what to replace numbers with\n",
        "        replace_with_digit=\"\",       # Specify what to replace digit characters with\n",
        "        replace_with_currency_symbol=\"\", # Specify what to replace currency symbols with\n",
        "        lang=\"en\"                    # Set the language to English for language-specific cleaning\n",
        "    )\n",
        "    return cleaned_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogqaH_4QduLj"
      },
      "outputs": [],
      "source": [
        "# Function to remove emojis and certain special symbols from a given string\n",
        "def remove_emojis(data):\n",
        "    # Compile a regular expression pattern to match a range of Unicode characters typically used for emojis and special symbols\n",
        "    emoji_pattern = re.compile(\n",
        "        \"[\"  # Start of character set\n",
        "\n",
        "        # Ranges for various emoji categories\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # Emoticons, such as smiley faces and other facial expressions\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # Miscellaneous symbols, pictographs, weather icons, etc.\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # Transport-related symbols, including vehicles, map symbols, etc.\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # Regional flags, often represented in pairs for country flags\n",
        "        u\"\\U00002500-\\U00002BEF\"  # Chinese characters, used in various contexts\n",
        "        u\"\\U00002702-\\U000027B0\"  # Miscellaneous symbols, including checkmarks and stars\n",
        "        u\"\\U000024C2-\\U0001F251\"  # Additional enclosed characters and compatibility symbols\n",
        "        u\"\\U0001F926-\\U0001F937\"  # Emojis depicting human gestures and actions\n",
        "        u\"\\U00010000-\\U0010FFFF\"  # Supplemental symbols and pictographs, including rare emoji\n",
        "        u\"\\u2640-\\u2642\"          # Gender symbols\n",
        "        u\"\\u2600-\\u2B55\"          # Various other symbols, including zodiac signs and geometric shapes\n",
        "        u\"\\u200D\"                 # Zero-width joiner, used for combining emoji sequences\n",
        "        u\"\\u23CF\"                 # Eject button symbol\n",
        "        u\"\\u23E9\"                 # Fast forward button\n",
        "        u\"\\u231A\"                 # Watch symbol\n",
        "        u\"\\uFE0F\"                 # Variation selector, used to specify emoji styles\n",
        "        u\"\\u3030\"                 # Wavy dash\n",
        "\n",
        "        \"]+\"                      # End of character set, match one or more occurrences\n",
        "        , re.UNICODE               # Enable Unicode matching\n",
        "    )\n",
        "\n",
        "    # Replace all matching emoji patterns in the input text with an empty string\n",
        "    return re.sub(emoji_pattern, '', data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE07amQKduOT"
      },
      "outputs": [],
      "source": [
        "# Remove stopwords\n",
        "def remove_stopwords(text):\n",
        "    stop_words = set(stopwords.words('english'))  # Get English stopwords\n",
        "    words = text.split()  # Tokenize the text\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]  # Remove stopwords\n",
        "    return ' '.join(filtered_words)   # Join the filtered words back into a string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMotxISEduQs"
      },
      "outputs": [],
      "source": [
        "# Remove mentions like @hello\n",
        "def remove_mentions(text):\n",
        "    mention_pattern = r\"@\\w+\"   # Regular expression pattern to match mentions\n",
        "    return re.sub(mention_pattern, '', text)  # Replace mentions with an empty string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1fSMu1Ud4Em"
      },
      "outputs": [],
      "source": [
        "# Function to clean the text column\n",
        "def clean_text(df, col):\n",
        "    df[col] = df[col].apply(func=clean_sentence)\n",
        "    df[col] = df[col].apply(func=remove_emojis)\n",
        "    df[col] = df[col].apply(func=remove_stopwords)\n",
        "    df[col] = df[col].apply(func=remove_mentions)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_LDOVNGd4HY"
      },
      "outputs": [],
      "source": [
        "# Apply the cleaning function to the dataset\n",
        "df = clean_text(df, 'text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQSXidntd4Jr",
        "outputId": "b4df898f-6372-4d04-cf9a-e3d495954dac"
      },
      "outputs": [],
      "source": [
        "# Displaying the first few rows of the cleaned dataset\n",
        "print(\"Cleaned Dataset Overview:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31TD1I5T128E"
      },
      "source": [
        "# DATA PREPARATION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMDMHDXdnXSm"
      },
      "outputs": [],
      "source": [
        "# Encoding labels\n",
        "label_enc = LabelEncoder()\n",
        "df['label_encoded'] = label_enc.fit_transform(df['label'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSatKYdNnXVo",
        "outputId": "a921cfb6-a132-4e03-b517-9ba2cb6a3f91"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary for original labels and their corresponding encoded values\n",
        "label_mapping_dict = dict(zip(label_enc.classes_, range(len(label_enc.classes_))))\n",
        "\n",
        "# Print the label mapping\n",
        "print(\"Label Mapping:\", label_mapping_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V4sfQnoiLsl",
        "outputId": "dd41067c-4311-486d-d82a-ea76dee2e0cc"
      },
      "outputs": [],
      "source": [
        "# Splitting data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label_encoded'], test_size=0.2, random_state=42)\n",
        "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JG7kooiomJy-"
      },
      "outputs": [],
      "source": [
        "# Creating a TF-IDF Vectorizer\n",
        "tfv = TfidfVectorizer(\n",
        "    min_df=3,\n",
        "    strip_accents='unicode',\n",
        "    token_pattern=r'\\w{1,}',\n",
        "    ngram_range=(1, 3),\n",
        "    sublinear_tf=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "mnAvEnOcnt5W",
        "outputId": "41ab0e66-5c23-4105-c4d8-65761d615598"
      },
      "outputs": [],
      "source": [
        "# Fit the TF-IDF vectorizer on the training data\n",
        "tfv.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGmHbPPWnt7_"
      },
      "outputs": [],
      "source": [
        "# Transform the training and test data\n",
        "X_train_tfv = tfv.transform(X_train)\n",
        "X_test_tfv = tfv.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvulc0jriLvD",
        "outputId": "5b65fb72-82f3-4a55-824e-440568c0d1a5"
      },
      "outputs": [],
      "source": [
        "# Display the shapes of the transformed datasets\n",
        "print(\"TF-IDF Training set shape:\", X_train_tfv.shape)\n",
        "print(\"TF-IDF Testing set shape:\", X_test_tfv.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sG6dWTE2jRsP",
        "outputId": "225be7c4-cc41-4d48-c088-8ea1c0c1654f"
      },
      "outputs": [],
      "source": [
        "# Saving the TF-IDF Vectorizer to a .pkl file\n",
        "joblib.dump(tfv, '../Artifacts/TFIDFVectorizer.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBRDGkTd12-c"
      },
      "source": [
        "# MODELS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4dIXr2t2rPL"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvNV1O5Xb2DI"
      },
      "outputs": [],
      "source": [
        "# Initialize the Random Forest Classifier\n",
        "model1 = RandomForestClassifier(n_estimators=100, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "n4UnFDCnb2EO",
        "outputId": "5ea66084-bc87-4c42-9baa-44cc82777c47"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model1.fit(X_train_tfv, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlSOBVVGb2Fq"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test set\n",
        "y_pred_rf = model1.predict(X_test_tfv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDMRvJXEb2Kb",
        "outputId": "703fc5b7-a4c9-4cf6-ca3c-4c466f188929"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_rf, target_names=label_enc.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vD3UbyQAb2Lp",
        "outputId": "01042850-43a1-4942-af01-8bf8515034c2"
      },
      "outputs": [],
      "source": [
        "# Accuracy score\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(f\"Accuracy Score: {accuracy_rf:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ws3hko8SuN6",
        "outputId": "032a0e07-c58c-4f94-ff80-e4423d08e6bd"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "joblib.dump(model1, '../Artifacts/RandomForest.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Btn1rlQocEMU"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "S-ZnDmrRC1dm",
        "outputId": "0a0f29b8-abf4-483c-f9b0-b33447cf4494"
      },
      "outputs": [],
      "source": [
        "# Creating and fitting the Naive Bayes model\n",
        "model2 = MultinomialNB()\n",
        "model2.fit(X_train_tfv, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7zdHRAqcKme"
      },
      "outputs": [],
      "source": [
        "# Making predictions\n",
        "y_pred_nb = model2.predict(X_test_tfv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN2_qiMwcKpR",
        "outputId": "b9ca2c8a-7d98-4aa6-ce60-1fe81b12e6cd"
      },
      "outputs": [],
      "source": [
        "# Evaluating the model\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_nb, target_names=label_enc.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa4NDbvPcKru",
        "outputId": "75114378-df9a-469b-ff78-81a7e78e4266"
      },
      "outputs": [],
      "source": [
        "# Accuracy score\n",
        "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "print(f\"Accuracy Score: {accuracy_nb:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdmfevAJTQv3",
        "outputId": "9ad12425-de21-45a8-8780-8e7f26f45914"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "joblib.dump(model2, '../Artifacts/NaiveBayes.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFFYpZPx2rMr"
      },
      "source": [
        "## SVM with OvO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLUJGgGAxHGw",
        "outputId": "6f429409-6e7a-45cc-c287-010e3b512aef"
      },
      "outputs": [],
      "source": [
        "# Function to train and evaluate SVM model with OvO strategy\n",
        "def train_and_evaluate_svm_ovo(X_train, X_test, y_train, y_test):\n",
        "    # Create a pipeline with MaxAbsScaler and SVM using OvO and probability=True\n",
        "    model3 = make_pipeline(MaxAbsScaler(), svm.SVC(kernel='linear', decision_function_shape='ovo', probability=True))\n",
        "\n",
        "    # Train the model\n",
        "    model3.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred_ovo = model3.predict(X_test)\n",
        "\n",
        "    # Evaluating the model\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred_ovo))\n",
        "\n",
        "    # Accuracy score\n",
        "    accuracy_ovo = accuracy_score(y_test, y_pred_ovo)\n",
        "    print(f\"Accuracy Score: {accuracy_ovo:.4f}\\n\")\n",
        "\n",
        "    # Calculate ROC AUC score for multi-class classification using predict_proba\n",
        "    roc_auc = roc_auc_score(y_test, model3.predict_proba(X_test), multi_class='ovr')\n",
        "\n",
        "    # Return the trained model and accuracy\n",
        "    return model3, accuracy_ovo, roc_auc\n",
        "\n",
        "# Train and evaluate the model, and get the accuracy\n",
        "model3, accuracy_ovo, roc_auc = train_and_evaluate_svm_ovo(X_train_tfv, X_test_tfv, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cGoboudUCWk",
        "outputId": "5676de8a-1821-441e-ff21-79c97e91fb89"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "joblib.dump(model3, '../Artifacts/SVM-OvO.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryIEtIGjD-2R"
      },
      "source": [
        "## SVM with OvR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6I6BwXGHw6xX",
        "outputId": "da0a296f-ab48-44a0-cf5d-83e43e0e13db"
      },
      "outputs": [],
      "source": [
        "# Function to train and evaluate SVM model with OvR strategy\n",
        "def train_and_evaluate_svm_ovr(X_train, X_test, y_train, y_test):\n",
        "    # Create a pipeline with MaxAbsScaler and SVM using OvR\n",
        "    model4 = make_pipeline(MaxAbsScaler(), svm.SVC(kernel='linear', decision_function_shape='ovr', probability=True))\n",
        "\n",
        "    # Train the model\n",
        "    model4.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred_ovr = model4.predict(X_test)\n",
        "\n",
        "    # Evaluating the model\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred_ovr, target_names=label_enc.classes_))\n",
        "\n",
        "    # Accuracy score\n",
        "    accuracy_ovr = accuracy_score(y_test, y_pred_ovr)\n",
        "    print(f\"Accuracy Score: {accuracy_ovr:.4f}\\n\")\n",
        "\n",
        "    # Calculate ROC AUC score for multi-class classification using predict_proba\n",
        "    roc_auc = roc_auc_score(y_test, model4.predict_proba(X_test), multi_class='ovr')\n",
        "\n",
        "    # Return the trained model and accuracy\n",
        "    return model4, accuracy_ovr, roc_auc\n",
        "\n",
        "# Train and evaluate the model, and get the accuracy\n",
        "model4, accuracy_ovr, roc_auc = train_and_evaluate_svm_ovr(X_train_tfv, X_test_tfv, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FWIUAmoWZY7",
        "outputId": "d4a9082c-4d80-4fb6-f4d7-6fde97967dff"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "joblib.dump(model4, '../Artifacts/SVM-OvR.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T9BWfFl2rR0"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RIvtG7aDEeY"
      },
      "outputs": [],
      "source": [
        "# Create the DMatrix for training and testing\n",
        "dtrain = xgb.DMatrix(X_train_tfv, label=y_train)\n",
        "dtest = xgb.DMatrix(X_test_tfv, label=y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDuaBGtHc605"
      },
      "outputs": [],
      "source": [
        "# Set parameters for XGBoost\n",
        "params = {\n",
        "    'objective': 'multi:softmax',  # Specify multi-class classification\n",
        "    'num_class': len(label_enc.classes_),  # Number of classes\n",
        "    'max_depth': 6,  # Maximum tree depth\n",
        "    'eta': 0.3,  # Learning rate\n",
        "    'eval_metric': 'mlogloss'  # Evaluation metric\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hvORra6c63a"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model5 = xgb.train(params, dtrain, num_boost_round=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeckBmuQc66B"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_pred_xgb = model5.predict(dtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCcTJqrrc68W",
        "outputId": "399c8294-e0e8-4d90-e311-85c2127fed55"
      },
      "outputs": [],
      "source": [
        "# Evaluating the model\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_xgb, target_names=label_enc.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0cdR_4yc69v",
        "outputId": "981ff4b3-842c-44e9-d4cb-b1ed8750386c"
      },
      "outputs": [],
      "source": [
        "# Accuracy score\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "print(f\"Accuracy Score: {accuracy_xgb:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuziXCY-Wg9a",
        "outputId": "8576886c-c7d9-42b7-a13f-73ee68093396"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "joblib.dump(model5, '../Artifacts/XGBoost.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biC9WGKm2rUr"
      },
      "source": [
        "## LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYpN4nKADFJV"
      },
      "outputs": [],
      "source": [
        "# Create the LightGBM dataset\n",
        "lgb_train = lgb.Dataset(X_train_tfv, label=y_train)\n",
        "lgb_test = lgb.Dataset(X_test_tfv, label=y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1i_NCTyRctPN"
      },
      "outputs": [],
      "source": [
        "# Set parameters for LightGBM\n",
        "lgb_params = {\n",
        "    'objective': 'multiclass',\n",
        "    'num_class': len(label_enc.classes_),  # Number of classes\n",
        "    'metric': 'multi_logloss',  # Evaluation metric\n",
        "    'boosting_type': 'gbdt',  # Gradient Boosting Decision Tree\n",
        "    'num_leaves': 31,  # Number of leaves in one tree\n",
        "    'learning_rate': 0.05,  # Learning rate\n",
        "    'feature_fraction': 0.9  # Fraction of features to use\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wM0Zu_rEctRs",
        "outputId": "7eda2a56-9c2c-4574-bb4f-c8dc1b8aa0b0"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model6 = lgb.train(lgb_params, lgb_train, num_boost_round=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PORhpOD5ctUN"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_pred_lgb = model6.predict(X_test_tfv)\n",
        "y_pred_lgb_classes = [np.argmax(x) for x in y_pred_lgb]  # Get the class with the highest probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDVjqkftctWp",
        "outputId": "44a662ea-4431-4224-80e8-c5427dadd857"
      },
      "outputs": [],
      "source": [
        "# Evaluating the model\n",
        "print(\"LightGBM Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_lgb_classes, target_names=label_enc.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8d4QaQkctZB",
        "outputId": "aac82e71-a563-4d01-9f4b-7de72ced6e99"
      },
      "outputs": [],
      "source": [
        "# Accuracy score\n",
        "accuracy_lgb = accuracy_score(y_test, y_pred_lgb_classes)\n",
        "print(f\"Accuracy Score: {accuracy_lgb:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjnnNL1xWpyx",
        "outputId": "3eed0859-9dc8-4302-dd98-f8f02d431f22"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "joblib.dump(model6, '../Artifacts/LightGBM.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z7ru6-Z3DnO"
      },
      "source": [
        "## CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXQ52MQ7DFpp"
      },
      "outputs": [],
      "source": [
        "# Initialize CatBoost Classifier\n",
        "model7 = CatBoostClassifier(\n",
        "    iterations=100,\n",
        "    depth=6,\n",
        "    learning_rate=0.3,\n",
        "    loss_function='MultiClass',\n",
        "    eval_metric='MultiClass',\n",
        "    random_seed=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DECHVGIOcjj0",
        "outputId": "a28a1977-9876-4811-ed18-eb4fb648bc8f"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model7.fit(X_train_tfv, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHCZPR7icjmb"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_pred_catboost = model7.predict(X_test_tfv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-VSdlX2cjpe",
        "outputId": "aebf7a6b-2c1b-49ad-a7b2-31dbcfb2db82"
      },
      "outputs": [],
      "source": [
        "# Evaluating the model\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_catboost, target_names=label_enc.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onvdDS5ycjrp",
        "outputId": "0761d433-670e-427a-d832-76861c2849ed"
      },
      "outputs": [],
      "source": [
        "# Accuracy score\n",
        "accuracy_catboost = accuracy_score(y_test, y_pred_catboost)\n",
        "print(f\"Accuracy Score: {accuracy_catboost:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp6ymmVNWuxN",
        "outputId": "8931de67-7cb6-4afc-a4e7-e87d88db3a67"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "joblib.dump(model7, '../Artifacts/CatBoost.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UHYRaQU13D8"
      },
      "source": [
        "# MODEL COMPARISON\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUxJ7LWq4J9j"
      },
      "outputs": [],
      "source": [
        "# Dictionary to store model names and their corresponding accuracies\n",
        "model_accuracies = {\n",
        "    'Random Forest': accuracy_rf,\n",
        "    'Naive Bayes': accuracy_nb,\n",
        "    'SVM (OvO)': accuracy_ovo,\n",
        "    'SVM (OvR)': accuracy_ovr,\n",
        "    'XGBoost': accuracy_xgb,\n",
        "    'LightGBM': accuracy_lgb,\n",
        "    'CatBoost': accuracy_catboost\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36w4DUZYHSAN"
      },
      "outputs": [],
      "source": [
        "# Extract model names and their accuracies\n",
        "models = list(model_accuracies.keys())\n",
        "accuracies = list(model_accuracies.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Es-FahhbiXeD"
      },
      "outputs": [],
      "source": [
        "# Create a bar graph\n",
        "sns.barplot(x=models, y=accuracies, palette='Set2')\n",
        "\n",
        "plt.ylim(0, 1)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Accuracies', pad=20)\n",
        "plt.xticks(rotation=90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yU1QiBy9iXgf"
      },
      "outputs": [],
      "source": [
        "# Annotate bars with accuracy values\n",
        "for i, v in enumerate(accuracies):\n",
        "    plt.text(i, v + 0.01, f\"{v:.4f}\", ha='center', va='bottom')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "nluZPc3sthuc",
        "outputId": "d84eecf7-7535-44f8-880e-19b0b4278494"
      },
      "outputs": [],
      "source": [
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HYpy9F5iTja"
      },
      "outputs": [],
      "source": [
        "# Find the model with the highest accuracy\n",
        "best_model = max(model_accuracies, key=model_accuracies.get)\n",
        "best_accuracy = model_accuracies[best_model]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHC7351i4MHN",
        "outputId": "1653d388-eafc-42c1-bca1-c69778a887f0"
      },
      "outputs": [],
      "source": [
        "# Print the best model and its accuracy\n",
        "print(f\"Best Model: {best_model} - Accuracy: {best_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roWdj05-HJwQ"
      },
      "source": [
        "# MODEL EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the model using joblib \n",
        "model = joblib.load('../Artifacts/SVM-OvO.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict on the test set \n",
        "y_pred_best = model.predict(X_test_tfv) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate evaluation metrics \n",
        "accuracy = accuracy_score(y_test, y_pred_best) \n",
        "precision = precision_score(y_test, y_pred_best, average='weighted') \n",
        "recall = recall_score(y_test, y_pred_best, average='weighted') \n",
        "f1 = f1_score(y_test, y_pred_best, average='weighted') \n",
        "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test_tfv), multi_class='ovr') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print metrics \n",
        "print(f'Accuracy: {accuracy:.4f}') \n",
        "print(f'Precision: {precision:.4f}') \n",
        "print(f'Recall: {recall:.4f}') \n",
        "print(f'F1 Score: {f1:.4f}') \n",
        "print(f'ROC AUC: {roc_auc:.4f}') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to display confusion matrix for multilabel classification with class names \n",
        "def plot_confusion_matrix(model, X_test, y_test, label_encoder):\n",
        "    y_pred = model.predict(X_test_tfv) \n",
        "    cm = multilabel_confusion_matrix(y_test, y_pred) \n",
        "    class_names = label_encoder.classes_  # Get class names from the label encoder\n",
        "\n",
        "    # Plot confusion matrix for each class \n",
        "    for i, matrix in enumerate(cm): \n",
        "        ax = sns.heatmap(matrix, annot=True, fmt='d', cmap='viridis') \n",
        "        plt.title(f'Confusion Matrix for {class_names[i]}') \n",
        "        plt.xlabel('Predicted') \n",
        "        plt.ylabel('Actual') \n",
        "        cbar = ax.collections[0].colorbar \n",
        "        cbar.ax.tick_params() \n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Call the function to plot the confusion matrix with class names \n",
        "plot_confusion_matrix(model, X_test, y_test, label_enc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Binarize the output labels for multi-class ROC \n",
        "y_test_binarized = label_binarize(y_test, classes=np.unique(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the decision function scores (SVM decision function for each class) \n",
        "y_score = model.decision_function(X_test_tfv) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to plot ROC curve for multiclass classification with customizable fonts and class names\n",
        "def plot_multiclass_roc_curve(y_test_binarized, y_score, class_names): \n",
        "    plt.figure(figsize=(10, 8)) \n",
        "    \n",
        "    # Plot ROC curve for each class\n",
        "    for i, class_name in enumerate(class_names): \n",
        "        fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_score[:, i]) \n",
        "        roc_auc = auc(fpr, tpr) \n",
        "        plt.plot(fpr, tpr, label=f'ROC curve for {class_name} (area = {roc_auc:.2f})') \n",
        "    \n",
        "    # Plot the diagonal line for reference \n",
        "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--') \n",
        "    \n",
        "    plt.xlabel('False Positive Rate') \n",
        "    plt.ylabel('True Positive Rate') \n",
        "    plt.title('Multiclass ROC Curve') \n",
        "    plt.legend(loc='lower right') \n",
        "    plt.grid() \n",
        "    plt.show() \n",
        "\n",
        "# Get decoded class names \n",
        "class_names = label_enc.inverse_transform(np.unique(y_test)) \n",
        "\n",
        "# Plot the ROC curve for multiclass classification \n",
        "plot_multiclass_roc_curve(y_test_binarized, y_score, class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIbuzi2B13BO"
      },
      "source": [
        "# SAMPLE PREDICTIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mg8vW7H5nXNs"
      },
      "outputs": [],
      "source": [
        "# Randomly select five samples from the training data (using X_train)\n",
        "sample_indices = np.random.choice(len(X_train), size=30, replace=False)\n",
        "sample_texts = X_train.iloc[sample_indices].tolist()\n",
        "actual_labels = y_train.iloc[sample_indices].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naC0FilTnXQM"
      },
      "outputs": [],
      "source": [
        "# Clean the sample texts using the same cleaning functions applied earlier\n",
        "cleaned_sample_texts = [clean_sentence(text) for text in sample_texts]\n",
        "cleaned_sample_texts = [remove_emojis(text) for text in cleaned_sample_texts]\n",
        "cleaned_sample_texts = [remove_stopwords(text) for text in cleaned_sample_texts]\n",
        "cleaned_sample_texts = [remove_mentions(text) for text in cleaned_sample_texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEDxwfo0nXS1"
      },
      "outputs": [],
      "source": [
        "# Transform the cleaned texts using the TF-IDF vectorizer\n",
        "sample_tfv = tfv.transform(cleaned_sample_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujEanLdynhxz"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the sample texts\n",
        "predictions = model.predict(sample_tfv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdTxHnQSnXVD"
      },
      "outputs": [],
      "source": [
        "# Decode the predictions back to original labels\n",
        "decoded_predictions = label_enc.inverse_transform(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQWrvfPqitNy",
        "outputId": "508fcdf0-6fb9-4b32-9b4d-9a679f5acd8a"
      },
      "outputs": [],
      "source": [
        "# Display the predictions in the desired format\n",
        "for i in range(len(sample_texts)):\n",
        "    print(f\"TEXT: {sample_texts[i]} \\nACTUAL: {label_enc.inverse_transform([actual_labels[i]])[0]} \\nPREDICTED: {decoded_predictions[i]}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVo1UnOQgF0v"
      },
      "outputs": [],
      "source": [
        "# Initialize a list to store the prediction history\n",
        "prediction_history = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb8GYM9ZhWab"
      },
      "outputs": [],
      "source": [
        "# Function to display the menu\n",
        "def display_menu():\n",
        "    print(\"\\nMenu:\")\n",
        "    print(\"1. Enter a sentence for prediction\")\n",
        "    print(\"2. View prediction history\")\n",
        "    print(\"0. Quit\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wawTuJfHhWc9"
      },
      "outputs": [],
      "source": [
        "# Function to get user input for predictions\n",
        "def get_user_input():\n",
        "    return input(\"\\nEnter a sentence for prediction: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxFLW7KyhWfO",
        "outputId": "00242f6c-ec44-40ea-f8ca-3df5c7b8a99e"
      },
      "outputs": [],
      "source": [
        "# Main program loop\n",
        "while True:\n",
        "    display_menu()\n",
        "    choice = input(\"\\nPlease select an option (0, 1, or 2): \").strip()\n",
        "\n",
        "    if choice == '1':\n",
        "        # Get user input for prediction\n",
        "        user_input = get_user_input()\n",
        "\n",
        "        # Clean the user-input text (assuming these functions are defined)\n",
        "        cleaned_user_sentence = clean_sentence(user_input)\n",
        "        cleaned_user_sentence = remove_emojis(cleaned_user_sentence)\n",
        "        cleaned_user_sentence = remove_stopwords(cleaned_user_sentence)\n",
        "        cleaned_user_sentence = remove_mentions(cleaned_user_sentence)\n",
        "\n",
        "        # Transform the cleaned text using the TF-IDF vectorizer\n",
        "        sample_tfv = tfv.transform([cleaned_user_sentence])\n",
        "\n",
        "        # Make prediction on the user-input text\n",
        "        prediction = model.predict(sample_tfv)\n",
        "\n",
        "        # Decode the prediction back to the original label\n",
        "        decoded_prediction = label_enc.inverse_transform(prediction)[0]\n",
        "\n",
        "        # Store the input and prediction in the history\n",
        "        prediction_history.append({'Text': user_input, 'Predicted Label': decoded_prediction})\n",
        "\n",
        "        # Display the prediction\n",
        "        print(f\"\\nPrediction: The entered text is classified as '{decoded_prediction}'\")\n",
        "\n",
        "    elif choice == '2':\n",
        "        # Display the prediction history\n",
        "        if prediction_history:\n",
        "            predicted_df = pd.DataFrame(prediction_history)\n",
        "            print(\"\\nPrediction History:\")\n",
        "            print(predicted_df)\n",
        "        else:\n",
        "            print(\"\\nNo predictions made yet\")\n",
        "\n",
        "    elif choice == '0':\n",
        "        print(\"\\nGoodbye!\")\n",
        "        break\n",
        "\n",
        "    else:\n",
        "        print(\"\\nInvalid choice\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
